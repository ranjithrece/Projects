{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "mount_file_id": "1ZqeW__fg24Kugvqhx5Kuc9tLmG4X-vOg",
      "authorship_tag": "ABX9TyPpC3KVjr/nijUCI5spmRBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjithrece/ranjithrece/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxzll6n3nQ_8"
      },
      "source": [
        "#**Chatbot**\n",
        "\n",
        "we are going to built a Chatbot with [keras](https://keras.io/)\n",
        "\n",
        "You can get the predefined pattern and response  file here [download](https://drive.google.com/file/d/1v_kEDymTKR4YBsl1l6RLw4OHpXMuIQXz/view?usp=sharing) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7X2yQKnAcFO"
      },
      "source": [
        "#importing neccesary modules\n",
        "import nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_GYdx9zCAIP"
      },
      "source": [
        "lem = WordNetLemmatizer()#create a inistane for lemmitizer\n",
        "intents = json.loads(open('intents.json').read())#loading the intents from json file\n",
        "\n",
        "#creating a empty list for seprating values\n",
        "words = []\n",
        "classes = set()\n",
        "docs = []\n",
        "ignore_wrds = ['?','!']\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1xnnSMXGMUk"
      },
      "source": [
        "#content - which type of question\n",
        "#pattern - user question\n",
        "#response - prestored response for user questions\n",
        "\n",
        "for intent in intents[\"intents\"]:#looping trough the intent \n",
        "  for pattern in intent['patterns']:\n",
        "\n",
        "    w = nltk.word_tokenize(pattern)# tokenizing the words\n",
        "    words.extend(w)\n",
        "\n",
        "    docs.append([w,intent['tag']])#creating a doc with tokenized words and their tag\n",
        "\n",
        "    classes.add(intent['tag'])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GI11ljPJgMZ"
      },
      "source": [
        "words = [lem.lemmatize(w.lower()) for w in words if w not in ignore_wrds]#lemmatizing the words eg. running to the base form of -> run\n",
        "\n",
        "classes = sorted(list(classes))#extracting the unique values\n",
        "words = sorted(list(set(words)))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2bRYHv4Ks_v"
      },
      "source": [
        "pickle.dump(words,open('words.pkl','wb'))#saving values in byte format\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWqAt7LMONjK"
      },
      "source": [
        "#creating a bag of words(one-hot) for training\n",
        "training  = []\n",
        "\n",
        "\n",
        "for doc in docs:\n",
        "\n",
        "    bag =[]\n",
        "    pattern_wrds = doc[0] #extracting the text\n",
        "    pattern_wrds = [lem.lemmatize(word.lower()) for word in pattern_wrds] #lemmatizing it\n",
        "\n",
        "    for w in words:  #loop through the words and creating bag\n",
        "      bag.append(1) if w in pattern_wrds else bag.append(0)\n",
        "\n",
        "    out = np.zeros(len(words))\n",
        "  \n",
        "    out[classes.index(doc[1])] = 1 #assg 1 to the respective tag in classes\n",
        "\n",
        "    training.append([bag,out])#appending the bag of words and bag of tag \n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "train_x = training[:,0]#bag of words\n",
        "train_y = training[:,1]#bag of tag"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv2a4XZJqsAT"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA1gwQ1Nj5hB",
        "outputId": "402cbd5d-b40d-42f1-8ff6-c598f8149f4e"
      },
      "source": [
        "model = Sequential(name='Chatbot_model')\n",
        "model.add(Dense(256,input_shape = (train_x.shape[1],),activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(train_y.shape[1],activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Chatbot_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 256)               22784     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 88)                5720      \n",
            "=================================================================\n",
            "Total params: 69,656\n",
            "Trainable params: 69,656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVzyjgGLlmwT",
        "outputId": "e4af3f63-28f2-4ff3-9136-0e897229a82a"
      },
      "source": [
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_x,train_y,epochs=50,batch_size=5)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 4ms/step - loss: 4.4488 - accuracy: 0.0106 \n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.2476 - accuracy: 0.2457\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9491 - accuracy: 0.2204\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.3598 - accuracy: 0.3334\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.6335 - accuracy: 0.2155\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.3533 - accuracy: 0.2498\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.8278 - accuracy: 0.3143\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.5022 - accuracy: 0.5147\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0712 - accuracy: 0.7057\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1745 - accuracy: 0.6850\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.8897 - accuracy: 0.7937\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.7672\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.9122\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8846\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.9330\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.9019\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9619\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9630\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9963\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9585\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9864\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9369\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9894\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8nI0CWFmi2f",
        "outputId": "fc60b409-655d-4f38-ac45-6ce28bd60143"
      },
      "source": [
        "model.save('model.h5',hist)#saving the model\n",
        "print('model saved')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "581zVNg8m4Cl"
      },
      "source": [
        "##Predicting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5A9DpTgz4GW"
      },
      "source": [
        "def clean_up(sent):\n",
        "  return  [lem.lemmatize(w.lower()) for w in  nltk.word_tokenize(sent)]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEENgSoA0aZp"
      },
      "source": [
        "def bow(sentence):#creating a bow for input sent\n",
        "  sentence = sentence\n",
        "  bow = np.zeros(len(words))\n",
        "\n",
        "  for s in sentence:\n",
        "    for i,w in enumerate(words):\n",
        "      if w == s:\n",
        "        bow [i] = 1 \n",
        "\n",
        "  return(bow)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywj8kith3isM"
      },
      "source": [
        "def predict(sent,model):\n",
        "  p = bow(sent)\n",
        "  pred = model.predict(np.array([p]))[0]\n",
        "  \n",
        "  thrsh = 0.30 #leave the predictions below this thrshold\n",
        "  res = [[i,j] for i,j in enumerate(pred) if j > thrsh]\n",
        "  res.sort(key= lambda x:x[1],reverse=True)#sorting the predictions\n",
        "  result_lis = []\n",
        "  for key,val in res:\n",
        "    result_lis.append({'intent':classes[key],'prob':str(val)})\n",
        "\n",
        "  return result_lis"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LV4aDGx5ndf",
        "outputId": "efc178f6-da18-41c5-d136-d3c858e1bdfc"
      },
      "source": [
        "predict('Hi',model)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'intent': 'greeting', 'prob': '0.5245994'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oRvce9j8f0r"
      },
      "source": [
        "def get_response(intn,int_json):\n",
        "  \n",
        "  tag = intn[0]['intent']\n",
        "  listOfTag = int_json['intents']\n",
        "  for i in listOfTag:\n",
        "    if (tag == i['tag']):\n",
        "      pred = random.choice(i['responses'])\n",
        "      break\n",
        "  return pred"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aFDizgL_GDZ"
      },
      "source": [
        "def chatbot(msg):\n",
        "  int = predict(msg,model)\n",
        "  res = get_response(int,intents)\n",
        "  return res"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HEDOlkLU_TFR",
        "outputId": "5a5e8e92-4470-4fca-e43e-874982232eb2"
      },
      "source": [
        "chatbot(\"hi there\")#getting response"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi there, how can I help?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS3J-Hp-CrvR"
      },
      "source": [
        "## Chatbot gui\n",
        "###Note:\n",
        "      Colab can't run below code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BHM-nHUCqAu"
      },
      "source": [
        "#Creating GUI with tkinter\n",
        "import tkinter\n",
        "from tkinter import *\n",
        "\n",
        "\n",
        "def send():\n",
        "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
        "    EntryBox.delete(\"0.0\",END)\n",
        "\n",
        "    if msg != '':\n",
        "        ChatLog.config(state=NORMAL)\n",
        "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
        "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
        "    \n",
        "        res = chatbot_response(msg)\n",
        "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
        "            \n",
        "        ChatLog.config(state=DISABLED)\n",
        "        ChatLog.yview(END)\n",
        " \n",
        "\n",
        "base = Tk()\n",
        "base.title(\"Hello\")\n",
        "base.geometry(\"400x500\")\n",
        "base.resizable(width=FALSE, height=FALSE)\n",
        "\n",
        "#Create Chat window\n",
        "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
        "\n",
        "ChatLog.config(state=DISABLED)\n",
        "\n",
        "#Bind scrollbar to Chat window\n",
        "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
        "ChatLog['yscrollcommand'] = scrollbar.set\n",
        "\n",
        "#Create Button to send message\n",
        "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
        "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
        "                    command= send )\n",
        "\n",
        "#Create the box to enter message\n",
        "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
        "#EntryBox.bind(\"<Return>\", send)\n",
        "\n",
        "\n",
        "#Place all components on the screen\n",
        "scrollbar.place(x=376,y=6, height=386)\n",
        "ChatLog.place(x=6,y=6, height=386, width=370)\n",
        "EntryBox.place(x=128, y=401, height=90, width=265)\n",
        "SendButton.place(x=6, y=401, height=90)\n",
        "\n",
        "base.mainloop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}